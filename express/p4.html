<!DOCTYPE html>
<html lang="en">
    <head>
        <script src="selection-portal/server.js"></script>
<title>Fairness in AI</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body {font-family: "Lato", sans-serif}
.mySlides {display: none}
h1 {text-align: center;}
p {text-align: center;}
form {text-align: center;}
div {
  border: 1px solid black;
  margin: 25px 50px 75px 100px;
  background-color: lightblue;
}
</style>

<body style="background-color:lightgrey;"> 
    <h1> Debriefing  </h1>
    
    <p> 
        Thank you for your participation.  In fact, you just participated in an experiment, in which our central goal
        was to understand human perceptions of what constitutes algorithmic fairness in an employment context.  We 
        simulated this scenario by asking a selector to choose an algorithm that would be used (a selector is, thus, 
        acting as an employer), and subsequently using the algorithm chosen by selectors to determine (as a function of 
        features we collect from prospective workers) who is “hired” to perform the task.  We are not, in actuality, 
        interested in the outcomes of the tasks, but in (a) what algorithms the selectors chose and why, and (b) which of 
        the algorithms are perceived as fair by the prospective workers. In order not to taint the results, we used several
        elements of deception in this experiment: <br><br>
        
        The nature of the task and our goals, as described above.
        We did not, in fact, always use the algorithm chosen by the selector, but did so 50% of the time.  
        The remaining times, we determined whether the prospective worker is selected to perform the task randomly.  
        We did this to enable us to tease out correlation between how favorable a particular algorithm is to a prospective 
        worker, the outcome chosen for the worker (whether they are selected or not), and the final perceptions of fairness. <br><br>
        
        <b>We ask to please not discuss this experiment with anyone.</b> <br><br>
        
        If you have any questions about the experiment, please feel free to contact Yevgeniy Vorobeychik, at <b>yvorobeychik@wustl.edu</b>.

    </p>


</body>>

    